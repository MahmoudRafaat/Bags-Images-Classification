# -*- coding: utf-8 -*-
"""Project mobileNet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PhVgi35yAXD5AJXQBUlM-s8cNmuwOVWV

# **Download Dataset from kaggle**
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("vencerlanz09/plastic-paper-garbage-bag-synthetic-images")

print("Path to dataset files:", path)

"""#**Import libraries i will use**"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models
import tensorflow as tf
from tensorflow import keras
from keras import Sequential
from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,BatchNormalization,Dropout
from sklearn.model_selection import train_test_split
# Import Data Science Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split

# Tensorflow Libraries
from tensorflow import keras
from tensorflow.keras import layers,models
from keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import Callback, EarlyStopping,ModelCheckpoint
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import Model

# System libraries
from pathlib import Path
import os.path

# Metrics
from sklearn.metrics import classification_report, confusion_matrix
import itertools

import os
from pathlib import Path
import matplotlib.pyplot as plt
from collections import Counter

from keras.layers import Flatten, Dense
from keras.models import Model
from keras.applications.mobilenet import MobileNet
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
import tensorflow as tf
from tensorflow import keras

"""
# **Show image sample**

"""

image_path = '/root/.cache/kagglehub/datasets/vencerlanz09/plastic-paper-garbage-bag-synthetic-images/versions/1/ImageClassesCombinedWithCOCOAnnotations/images_raw/00000010.jpg'
# Read the image
img = mpimg.imread(image_path)

print(img.shape)
# Display the image
plt.imshow(img)
plt.axis('off')  # Turn off axis numbers
plt.show()

"""# **check images size in every class**"""

# Path to your dataset
dataset_path = Path('/root/.cache/kagglehub/datasets/vencerlanz09/plastic-paper-garbage-bag-synthetic-images/versions/1/Bag Classes/Bag Classes')

# Initialize a Counter to store class counts
class_counts = Counter()

# Iterate through each class folder in the dataset
for class_folder in os.listdir(dataset_path):
    class_folder_path = dataset_path / class_folder
    if os.path.isdir(class_folder_path):
        # Count the number of files in each class folder
        num_files = len(os.listdir(class_folder_path))
        class_counts[class_folder] = num_files

# Plot the class counts
plt.figure(figsize=(10, 6))
plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')
plt.xlabel('Classes')
plt.ylabel('Number of Images')
plt.title('Class Distribution')
plt.xticks(rotation=45)
plt.show()

image_dir = Path(dataset_path)

# Get filepaths and labels
filepaths = list(image_dir.glob(r'**/*.JPG')) + list(image_dir.glob(r'**/*.jpg')) + list(image_dir.glob(r'**/*.png')) + list(image_dir.glob(r'**/*.png'))

labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))

filepaths = pd.Series(filepaths, name='Filepath').astype(str)
labels = pd.Series(labels, name='Label')

# Concatenate filepaths and labels
image_df = pd.concat([filepaths, labels], axis=1)

"""# **show sample of images with labels**"""

random_index = np.random.randint(0, len(image_df), 16)
print(random_index)
fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10),
                        subplot_kw={'xticks': [], 'yticks': []})

for i, ax in enumerate(axes.flat):
    ax.imshow(plt.imread(image_df.Filepath[random_index[i]]))
    ax.set_title(image_df.Label[random_index[i]])
plt.tight_layout()
plt.show()

"""# **Spilt data into 80% train and  20% test**"""

train_df, test_df = train_test_split(image_df, test_size=0.2, shuffle=True, random_state=42)
train_df.shape

test_df.shape

train_set = ImageDataGenerator(
        rescale=1./255,
    validation_split=0.2

)

test_set = ImageDataGenerator(
    rescale=1./255,
)

# Split the data into three categories.
train_images = train_set.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='training'
)

val_images = train_set.flow_from_dataframe(
    dataframe=train_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=True,
    seed=42,
    subset='validation'
)

test_images = test_set.flow_from_dataframe(
    dataframe=test_df,
    x_col='Filepath',
    y_col='Label',
    target_size=(224, 224),
    color_mode='rgb',
    class_mode='categorical',
    batch_size=32,
    shuffle=False
)

"""# **First using MobileNet pertrained CNN model**"""

# Load the MobileNet base model
base_model = MobileNet(input_shape=(224, 224, 3), include_top=False, weights='imagenet')

# Freeze the base model layers to prevent feature extraction training
for layer in base_model.layers:
    layer.trainable = False


# Define new model
X = Flatten()(base_model.output)
X = Dense(128, activation='relu')(X)  # Reduced neurons
X = Dropout(0.5)(X)
X = Dense(3, activation='softmax')(X)  # Final classification layer for 3 classes

# Build the model
model = Model(inputs=base_model.input, outputs=X)

# Compile the model with a high learning rate
model.compile(optimizer=Adam(learning_rate=0.005),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Print the model summary
model.summary()

# ModelCheckpoint callback
model_checkpoint = ModelCheckpoint(
    filepath='best_model.keras',     # Save model to this file
    monitor='val_loss', # Monitor validation loss
    save_best_only=True, # Save the model only when validation loss improves
    verbose=1,          # Print messages when saving the model
    save_weights_only=False,  # Save the entire model (architecture + weights)
    mode='min',         # 'min' means to save the model when validation loss is minimized
)

reduce_lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)


# Train the model for exactly 10 epochs
history = model.fit(
    train_images,
    epochs=20,                     # Train for up to 10 epochs
    validation_data=val_images,
    callbacks=[reduce_lr_callback, model_checkpoint]  # Add ReduceLROnPlateau, ModelCheckpoint, and EarlyStopping
)

# Retrieve final training accuracy and loss
train_acc = history.history['accuracy'][-1]
train_loss = history.history['loss'][-1]
print(f"Final Training Accuracy: {train_acc:.4f}")
print(f"Final Training Loss: {train_loss:.4f}")
#Validation set Accuracy
val_acc = history.history['val_accuracy'][-1]
val_loss = history.history['val_loss'][-1]
print(f"Final Validation Accuracy: {val_acc:.4f}")
print(f"Final Validation Loss: {val_loss:.4f}")

# Evaluate the model on the testing set
test_loss, test_acc = model.evaluate(test_images)
print(f"Testing Accuracy: {test_acc:.4f}")
print(f"Testing Loss: {test_loss:.4f}")

import matplotlib.pyplot as plt


loss = history.history['loss']
val_loss = history.history['val_loss']

accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']

epochs = range(len(history.history['loss']))

# Plot loss
plt.plot(epochs, loss, label='training_loss')
plt.plot(epochs, val_loss, label='val_loss')
plt.title('Loss')
plt.xlabel('Epochs')
plt.legend()

# Plot accuracy
plt.figure()
plt.plot(epochs, accuracy, label='training_accuracy')
plt.plot(epochs, val_accuracy, label='val_accuracy')
plt.title('Accuracy')
plt.xlabel('Epochs')
plt.legend();

pred = model.predict(test_images)
pred = np.argmax(pred,axis=1)

# Map the label
labels = (train_images.class_indices)
labels = dict((v,k) for k,v in labels.items())
pred = [labels[k] for k in pred]

# Display the result
print(f'The first 10 predictions: {pred[:10]}')

y_test = list(test_df.Label)
report = classification_report(y_test, pred, output_dict=True)
df = pd.DataFrame(report).transpose()
df

random_index = np.random.randint(0, len(test_df) - 1, 15)
fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(25, 15),
                        subplot_kw={'xticks': [], 'yticks': []})

for i, ax in enumerate(axes.flat):
    ax.imshow(plt.imread(test_df.Filepath.iloc[random_index[i]]))
    if test_df.Label.iloc[random_index[i]] == pred[random_index[i]]:
        color = "green"
    else:
        color = "red"
    ax.set_title(f"True: {test_df.Label.iloc[random_index[i]]}\nPredicted: {pred[random_index[i]]}", color=color)
plt.show()
plt.tight_layout()

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Class names
class_names = ['Garbage ', 'Paper', 'Plastic ']

# Compute confusion matrix
cm = confusion_matrix(y_test, pred)

# Display confusion matrix with class names
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)
disp.plot(cmap=plt.cm.viridis)  # You can choose any colormap you like
plt.title("Confusion Matrix")
plt.show()

# Import required libraries
import tensorflow as tf
from tensorflow.keras.applications.mobilenet import preprocess_input
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from google.colab import files
import numpy as np
import matplotlib.pyplot as plt

# Function to upload an image file from the local device
def upload_image():
    print("Please upload an image:")
    uploaded = files.upload()  # Upload file(s) from your device
    image_path = list(uploaded.keys())[0]  # Get the uploaded file name
    print(f"Image {image_path} uploaded successfully!")
    return image_path

# Function to preprocess the image and predict the class
def predict_image(image_path, model, class_labels):
    # Load and preprocess the image
    img = load_img(image_path, target_size=(224, 224))  # Resize to 224x224 for MobileNet
    img_array = img_to_array(img)  # Convert to numpy array
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    img_array = preprocess_input(img_array)  # Preprocess for MobileNet

    # Predict the class
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions, axis=1)[0]  # Get the highest probability index

    # Display the image and prediction
    plt.imshow(plt.imread(image_path))
    plt.title(f"Predicted Class: {class_labels[predicted_class]}")
    plt.axis('off')
    plt.show()

    # Print detailed results
    print(f"Prediction Probabilities: {predictions}")
    print(f"Predicted Class: {class_labels[predicted_class]}")

# Load your trained model
model_path = "best_model.keras"  # Path to your saved model
model = tf.keras.models.load_model(model_path)
print("Model loaded successfully!")

# Define your class labels
class_labels = ['Garbage ', 'Paper', 'Plastic ']

# Upload an image and make a prediction
image_path = upload_image()  # Upload image file
predict_image(image_path, model, class_labels)  # Predict the class

model_path = "best_model.keras"  # Path to your saved model
model = tf.keras.models.load_model(model_path)
print("Model loaded successfully!")

# Define your class labels
class_labels = ['Garbage ', 'Paper', 'Plastic ']

# Upload an image and make a prediction
image_path = upload_image()  # Upload image file
predict_image(image_path, model, class_labels)  # Predict the class